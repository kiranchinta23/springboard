{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='we.png'>\n",
    "<img src='analogy.png'>\n",
    "\n",
    "- converting 300 dimensions to 2 dimens\n",
    "<img src='2d.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Implementing Word Embedding </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps to implement word embedding\n",
    "1. vocab size\n",
    "2. one hot representation\n",
    "3. embedding Representation \n",
    "    - pad_sequences\n",
    "    - Sequential Model\n",
    "    - layer with dimensions (features)\n",
    "<img src ='232.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word embedding techniques using embedding layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences\n",
    "sents=['the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of developer',\n",
    "     'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of developer',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: vocabulary size\n",
    "voc_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: one hot representation\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "sents_onehot=[one_hot(sent,voc_size) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[561, 137, 274, 916],\n",
       " [561, 137, 274, 676],\n",
       " [561, 405, 274, 700],\n",
       " [844, 616, 969, 672, 999],\n",
       " [456, 561, 579, 274, 999],\n",
       " [635, 22, 950, 672]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Embedding layer\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0, 561, 137, 274, 916],\n",
       "       [  0,   0,   0,   0, 561, 137, 274, 676],\n",
       "       [  0,   0,   0,   0, 561, 405, 274, 700],\n",
       "       [  0,   0,   0, 844, 616, 969, 672, 999],\n",
       "       [  0,   0,   0, 456, 561, 579, 274, 999],\n",
       "       [  0,   0,   0,   0, 635,  22, 950, 672]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_length=8\n",
    "\n",
    "embedded_docs=pad_sequences(sents_onehot,padding='pre',maxlen=sent_length)\n",
    "\n",
    "embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "# vocab size - no of columns --> no of words\n",
    "# dim (2nd paramerter) --> no of rows --> no of features\n",
    "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
    "\n",
    "# adam optimizer, mse error\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 10)             10000     \n",
      "=================================================================\n",
      "Total params: 10,000\n",
      "Trainable params: 10,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [-0.04489905  0.0448199   0.04858373 -0.00115131  0.03810059\n",
      "    0.00381806 -0.0154647   0.00492752 -0.01108494  0.01081719]\n",
      "  [-0.019838    0.0432758  -0.03252403  0.04544988 -0.01862431\n",
      "   -0.03500415 -0.02742245 -0.04164118  0.04620595 -0.01324952]\n",
      "  [ 0.01059176  0.00477562 -0.02030197 -0.04631165 -0.01681845\n",
      "    0.0252024   0.04952595 -0.00351278 -0.04620087  0.00945089]\n",
      "  [-0.03323106  0.02133368 -0.03055931  0.02604817  0.00768939\n",
      "    0.01120262  0.04542447  0.02127612 -0.03154254 -0.02830284]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [-0.04489905  0.0448199   0.04858373 -0.00115131  0.03810059\n",
      "    0.00381806 -0.0154647   0.00492752 -0.01108494  0.01081719]\n",
      "  [-0.019838    0.0432758  -0.03252403  0.04544988 -0.01862431\n",
      "   -0.03500415 -0.02742245 -0.04164118  0.04620595 -0.01324952]\n",
      "  [ 0.01059176  0.00477562 -0.02030197 -0.04631165 -0.01681845\n",
      "    0.0252024   0.04952595 -0.00351278 -0.04620087  0.00945089]\n",
      "  [-0.00606812  0.02532997  0.03021378 -0.01968423  0.04305693\n",
      "    0.0367288  -0.02514922 -0.03322931  0.01579971 -0.01602889]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [-0.04489905  0.0448199   0.04858373 -0.00115131  0.03810059\n",
      "    0.00381806 -0.0154647   0.00492752 -0.01108494  0.01081719]\n",
      "  [-0.04176332  0.03960408 -0.03361732 -0.03988501  0.00178773\n",
      "   -0.01428311  0.03012767 -0.00920125 -0.04426144  0.00907875]\n",
      "  [ 0.01059176  0.00477562 -0.02030197 -0.04631165 -0.01681845\n",
      "    0.0252024   0.04952595 -0.00351278 -0.04620087  0.00945089]\n",
      "  [-0.01174783 -0.01297253 -0.00536368  0.04351011  0.0293684\n",
      "   -0.03548219  0.02711388 -0.02607775  0.04246563  0.01548182]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [-0.0446513  -0.0214177   0.0108335  -0.04857937 -0.00871589\n",
      "    0.04082689 -0.03660216  0.03139087  0.03992924  0.04263021]\n",
      "  [-0.04574997 -0.02313331  0.00488927  0.00824338 -0.03575767\n",
      "    0.0039051  -0.01948768  0.00846599  0.03715051  0.03783775]\n",
      "  [ 0.03013262  0.03157653 -0.00356474 -0.0112958  -0.01993006\n",
      "   -0.04001707 -0.02311643  0.00668166 -0.0384742  -0.01840155]\n",
      "  [ 0.03326145  0.01709925 -0.01706133  0.00044578 -0.0167995\n",
      "    0.0401361   0.04462034 -0.01393256 -0.03951722  0.00082556]\n",
      "  [ 0.04488904 -0.03364326 -0.02135007  0.00426317  0.04821854\n",
      "    0.03350763  0.02359704 -0.03163113 -0.04767827 -0.00927317]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [-0.03492985  0.00435312 -0.03093774  0.04374385 -0.01216418\n",
      "    0.02711071 -0.02007816 -0.04989488  0.01785759  0.01910884]\n",
      "  [-0.04489905  0.0448199   0.04858373 -0.00115131  0.03810059\n",
      "    0.00381806 -0.0154647   0.00492752 -0.01108494  0.01081719]\n",
      "  [ 0.04839596 -0.01324099  0.04130527 -0.00909034  0.04997886\n",
      "   -0.01192359 -0.01846608 -0.03439646 -0.03899091 -0.02056408]\n",
      "  [ 0.01059176  0.00477562 -0.02030197 -0.04631165 -0.01681845\n",
      "    0.0252024   0.04952595 -0.00351278 -0.04620087  0.00945089]\n",
      "  [ 0.04488904 -0.03364326 -0.02135007  0.00426317  0.04821854\n",
      "    0.03350763  0.02359704 -0.03163113 -0.04767827 -0.00927317]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]\n",
      "  [ 0.01533205  0.02716713  0.04998091  0.00492986 -0.02696809\n",
      "    0.00625867  0.0345096  -0.00894114 -0.04185306 -0.04847585]\n",
      "  [-0.02225108 -0.01670187  0.03052824 -0.0147543   0.03775271\n",
      "    0.0093703  -0.03258512 -0.0159765  -0.02677205 -0.02089833]\n",
      "  [ 0.02554909 -0.03509021 -0.03414433  0.02095468  0.03943402\n",
      "    0.04157079  0.00371385 -0.00779772  0.03849487  0.03660219]\n",
      "  [ 0.03326145  0.01709925 -0.01706133  0.00044578 -0.0167995\n",
      "    0.0401361   0.04462034 -0.01393256 -0.03951722  0.00082556]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 561, 137, 274, 916])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input Tensor(\"embedding_1_input:0\", shape=(None, 8), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
      "[[[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]]\n",
      "\n",
      " [[ 0.04284041  0.01286211 -0.01976429 -0.04456614 -0.0169171\n",
      "   -0.02869103 -0.01046633  0.04654875 -0.031579   -0.03542005]]\n",
      "\n",
      " [[-0.04489905  0.0448199   0.04858373 -0.00115131  0.03810059\n",
      "    0.00381806 -0.0154647   0.00492752 -0.01108494  0.01081719]]\n",
      "\n",
      " [[-0.019838    0.0432758  -0.03252403  0.04544988 -0.01862431\n",
      "   -0.03500415 -0.02742245 -0.04164118  0.04620595 -0.01324952]]\n",
      "\n",
      " [[ 0.01059176  0.00477562 -0.02030197 -0.04631165 -0.01681845\n",
      "    0.0252024   0.04952595 -0.00351278 -0.04620087  0.00945089]]\n",
      "\n",
      " [[-0.03323106  0.02133368 -0.03055931  0.02604817  0.00768939\n",
      "    0.01120262  0.04542447  0.02127612 -0.03154254 -0.02830284]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
