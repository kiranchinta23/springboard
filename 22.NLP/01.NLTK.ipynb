{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Tokenization</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#ltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpse='''Not long ago, I came across a little-known speech titled, “You and Your Research”.\n",
    "\n",
    "The speech had been delivered in 1986 by Richard Hamming, an accomplished mathematician and computer engineer, as part of an internal series of talks given at Bell Labs. I had never heard of Hamming, the internal lecture series at Bell Labs, or this particular speech. And yet, as I read the transcript, I came across one useful insight after another.\n",
    "\n",
    "After reading that talk, I got to thinking… what other great talks and speeches are out there that I've never heard?\n",
    "\n",
    "I've been slowly searching for answers to that question and the result is this list of my favorite interesting and insightful talks that are not widely known. You may see a few famous speeches on this list, but my guess is that most people are not aware of many of them—just as I wasn't when I first started looking around.\n",
    "\n",
    "As far as I know this is the only place where you can read transcripts of these speeches in one place.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(corpse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=nltk.word_tokenize(corpse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not long ago, I came across a little-known speech titled, “You and Your Research”.',\n",
       " 'The speech had been delivered in 1986 by Richard Hamming, an accomplished mathematician and computer engineer, as part of an internal series of talks given at Bell Labs.',\n",
       " 'I had never heard of Hamming, the internal lecture series at Bell Labs, or this particular speech.',\n",
       " 'And yet, as I read the transcript, I came across one useful insight after another.',\n",
       " \"After reading that talk, I got to thinking… what other great talks and speeches are out there that I've never heard?\",\n",
       " \"I've been slowly searching for answers to that question and the result is this list of my favorite interesting and insightful talks that are not widely known.\",\n",
       " \"You may see a few famous speeches on this list, but my guess is that most people are not aware of many of them—just as I wasn't when I first started looking around.\",\n",
       " 'As far as I know this is the only place where you can read transcripts of these speeches in one place.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not',\n",
       " 'long',\n",
       " 'ago',\n",
       " ',',\n",
       " 'I',\n",
       " 'came',\n",
       " 'across',\n",
       " 'a',\n",
       " 'little-known',\n",
       " 'speech',\n",
       " 'titled',\n",
       " ',',\n",
       " '“',\n",
       " 'You',\n",
       " 'and',\n",
       " 'Your',\n",
       " 'Research',\n",
       " '”',\n",
       " '.',\n",
       " 'The',\n",
       " 'speech',\n",
       " 'had',\n",
       " 'been',\n",
       " 'delivered',\n",
       " 'in',\n",
       " '1986',\n",
       " 'by',\n",
       " 'Richard',\n",
       " 'Hamming',\n",
       " ',',\n",
       " 'an',\n",
       " 'accomplished',\n",
       " 'mathematician',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'engineer',\n",
       " ',',\n",
       " 'as',\n",
       " 'part',\n",
       " 'of',\n",
       " 'an',\n",
       " 'internal',\n",
       " 'series',\n",
       " 'of',\n",
       " 'talks',\n",
       " 'given',\n",
       " 'at',\n",
       " 'Bell',\n",
       " 'Labs',\n",
       " '.',\n",
       " 'I',\n",
       " 'had',\n",
       " 'never',\n",
       " 'heard',\n",
       " 'of',\n",
       " 'Hamming',\n",
       " ',',\n",
       " 'the',\n",
       " 'internal',\n",
       " 'lecture',\n",
       " 'series',\n",
       " 'at',\n",
       " 'Bell',\n",
       " 'Labs',\n",
       " ',',\n",
       " 'or',\n",
       " 'this',\n",
       " 'particular',\n",
       " 'speech',\n",
       " '.',\n",
       " 'And',\n",
       " 'yet',\n",
       " ',',\n",
       " 'as',\n",
       " 'I',\n",
       " 'read',\n",
       " 'the',\n",
       " 'transcript',\n",
       " ',',\n",
       " 'I',\n",
       " 'came',\n",
       " 'across',\n",
       " 'one',\n",
       " 'useful',\n",
       " 'insight',\n",
       " 'after',\n",
       " 'another',\n",
       " '.',\n",
       " 'After',\n",
       " 'reading',\n",
       " 'that',\n",
       " 'talk',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'to',\n",
       " 'thinking…',\n",
       " 'what',\n",
       " 'other',\n",
       " 'great',\n",
       " 'talks',\n",
       " 'and',\n",
       " 'speeches',\n",
       " 'are',\n",
       " 'out',\n",
       " 'there',\n",
       " 'that',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'never',\n",
       " 'heard',\n",
       " '?',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'been',\n",
       " 'slowly',\n",
       " 'searching',\n",
       " 'for',\n",
       " 'answers',\n",
       " 'to',\n",
       " 'that',\n",
       " 'question',\n",
       " 'and',\n",
       " 'the',\n",
       " 'result',\n",
       " 'is',\n",
       " 'this',\n",
       " 'list',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'interesting',\n",
       " 'and',\n",
       " 'insightful',\n",
       " 'talks',\n",
       " 'that',\n",
       " 'are',\n",
       " 'not',\n",
       " 'widely',\n",
       " 'known',\n",
       " '.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'see',\n",
       " 'a',\n",
       " 'few',\n",
       " 'famous',\n",
       " 'speeches',\n",
       " 'on',\n",
       " 'this',\n",
       " 'list',\n",
       " ',',\n",
       " 'but',\n",
       " 'my',\n",
       " 'guess',\n",
       " 'is',\n",
       " 'that',\n",
       " 'most',\n",
       " 'people',\n",
       " 'are',\n",
       " 'not',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'many',\n",
       " 'of',\n",
       " 'them—just',\n",
       " 'as',\n",
       " 'I',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'when',\n",
       " 'I',\n",
       " 'first',\n",
       " 'started',\n",
       " 'looking',\n",
       " 'around',\n",
       " '.',\n",
       " 'As',\n",
       " 'far',\n",
       " 'as',\n",
       " 'I',\n",
       " 'know',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'only',\n",
       " 'place',\n",
       " 'where',\n",
       " 'you',\n",
       " 'can',\n",
       " 'read',\n",
       " 'transcripts',\n",
       " 'of',\n",
       " 'these',\n",
       " 'speeches',\n",
       " 'in',\n",
       " 'one',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Stemmming and Lemmatization </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='stem.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not long ago , I came across little-known speech titl , “ you your research ” .',\n",
       " 'the speech deliv 1986 richard ham , accomplish mathematician comput engin , part intern seri talk given bell lab .',\n",
       " 'I never heard ham , intern lectur seri bell lab , particular speech .',\n",
       " 'and yet , I read transcript , I came across one use insight anoth .',\n",
       " \"after read talk , I got thinking… great talk speech I 've never heard ?\",\n",
       " \"I 've slowli search answer question result list favorit interest insight talk wide known .\",\n",
       " \"you may see famou speech list , guess peopl awar mani them—just I n't I first start look around .\",\n",
       " 'As far I know place read transcript speech one place .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not long ago , I came across little-known speech titled , “ You Your Research ” .',\n",
       " 'The speech delivered 1986 Richard Hamming , accomplished mathematician computer engineer , part internal series talk given Bell Labs .',\n",
       " 'I never heard Hamming , internal lecture series Bell Labs , particular speech .',\n",
       " 'And yet , I read transcript , I came across one useful insight another .',\n",
       " \"After reading talk , I got thinking… great talk speech I 've never heard ?\",\n",
       " \"I 've slowly searching answer question result list favorite interesting insightful talk widely known .\",\n",
       " \"You may see famous speech list , guess people aware many them—just I n't I first started looking around .\",\n",
       " 'As far I know place read transcript speech one place .']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Bag of words</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='bow.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph='''Not long ago, I came across a little-known speech titled, “You and Your Research”.\n",
    "\n",
    "The speech had been delivered in 1986 by Richard Hamming, an accomplished mathematician and computer engineer, as part of an internal series of talks given at Bell Labs. I had never heard of Hamming, the internal lecture series at Bell Labs, or this particular speech. And yet, as I read the transcript, I came across one useful insight after another.\n",
    "\n",
    "After reading that talk, I got to thinking… what other great talks and speeches are out there that I've never heard?\n",
    "\n",
    "I've been slowly searching for answers to that question and the result is this list of my favorite interesting and insightful talks that are not widely known. You may see a few famous speeches on this list, but my guess is that most people are not aware of many of them—just as I wasn't when I first started looking around.\n",
    "\n",
    "As far as I know this is the only place where you can read transcripts of these speeches in one place.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning texts libraries\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "# can do lemmatizer or stemming\n",
    "sentences=nltk.sent_tokenize(paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=1500)\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawbacks:\n",
    "no particular importance to the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>TF-IDF</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='tfidf.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph='''Not long ago, I came across a little-known speech titled, “You and Your Research”.\n",
    "\n",
    "The speech had been delivered in 1986 by Richard Hamming, an accomplished mathematician and computer engineer, as part of an internal series of talks given at Bell Labs. I had never heard of Hamming, the internal lecture series at Bell Labs, or this particular speech. And yet, as I read the transcript, I came across one useful insight after another.\n",
    "\n",
    "After reading that talk, I got to thinking… what other great talks and speeches are out there that I've never heard?\n",
    "\n",
    "I've been slowly searching for answers to that question and the result is this list of my favorite interesting and insightful talks that are not widely known. You may see a few famous speeches on this list, but my guess is that most people are not aware of many of them—just as I wasn't when I first started looking around.\n",
    "\n",
    "As far as I know this is the only place where you can read transcripts of these speeches in one place.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for cleaning text\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv=TfidfVectorizer()\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.3089861 , 0.36868416, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3089861 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3089861 , 0.        , 0.        ,\n",
       "        0.        , 0.36868416, 0.36868416, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.36868416, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18423545, 0.        ,\n",
       "        0.        , 0.        , 0.36868416, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.28531173, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2391135 , 0.        , 0.28531173,\n",
       "        0.28531173, 0.28531173, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28531173, 0.        , 0.        , 0.        ,\n",
       "        0.2391135 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2391135 , 0.        , 0.        , 0.2391135 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28531173, 0.        , 0.        , 0.        , 0.28531173,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28531173, 0.        ,\n",
       "        0.        , 0.2391135 , 0.        , 0.14257334, 0.        ,\n",
       "        0.20633533, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31306602, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31306602, 0.31306602, 0.        , 0.        , 0.        ,\n",
       "        0.31306602, 0.        , 0.        , 0.31306602, 0.37355234,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31306602, 0.        , 0.        ,\n",
       "        0.37355234, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31306602, 0.        , 0.18666813, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.30578087, 0.        , 0.36485966, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30578087, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.36485966, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30578087, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30578087,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30578087, 0.36485966,\n",
       "        0.        , 0.36485966],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35929196, 0.35929196, 0.        ,\n",
       "        0.        , 0.30111471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30111471, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.35929196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.17954206, 0.        ,\n",
       "        0.51967457, 0.35929196, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.30250634,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30250634,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30250634, 0.30250634,\n",
       "        0.        , 0.        , 0.25352392, 0.        , 0.        ,\n",
       "        0.25352392, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30250634, 0.        ,\n",
       "        0.        , 0.        , 0.30250634, 0.        , 0.30250634,\n",
       "        0.        , 0.        , 0.30250634, 0.        , 0.        ,\n",
       "        0.21877034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30250634, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28925319, 0.28925319, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.28925319, 0.        , 0.        ,\n",
       "        0.28925319, 0.        , 0.        , 0.        , 0.28925319,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24241674, 0.        , 0.        , 0.28925319, 0.28925319,\n",
       "        0.        , 0.28925319, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28925319, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.28925319, 0.        , 0.        , 0.14454293, 0.28925319,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34592271, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.34592271, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28991023, 0.        ,\n",
       "        0.        , 0.        , 0.69184543, 0.        , 0.28991023,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1728613 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28991023, 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
